{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Декомпозиция Клементса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Clements unitary decomposition\n",
    "\"\"\"\n",
    "\n",
    "from typing import NamedTuple, List, Tuple\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def mzi_matrix(\n",
    "    dim: int,\n",
    "    target: Tuple[int, int],\n",
    "    theta: float,\n",
    "    phi: float,\n",
    "    dtype=torch.complex128,\n",
    "    device='cpu'\n",
    ") -> Tensor:\n",
    "    \"\"\"Matrix form of a Mach-Zehnder interferometer using PyTorch.\"\"\"\n",
    "    m, n = target\n",
    "    if n - m != 1:\n",
    "        raise ValueError(\"m and n must be consecutive integers.\")\n",
    "\n",
    "    u_mzi = torch.eye(dim, dtype=dtype, device=device)\n",
    "\n",
    "    theta_t = torch.tensor(theta, dtype=torch.float32, device=device, requires_grad=False)\n",
    "    phi_t = torch.tensor(phi, dtype=torch.float32, device=device, requires_grad=False)\n",
    "\n",
    "    global_phase = torch.exp(1j * theta_t)\n",
    "    cos_t = torch.cos(theta_t)\n",
    "    sin_t = torch.sin(theta_t)\n",
    "    exp_phi = torch.exp(1j * phi_t)\n",
    "\n",
    "    u_mzi[m, m] = global_phase * exp_phi * cos_t\n",
    "    u_mzi[m, n] = global_phase * 1j * sin_t\n",
    "    u_mzi[n, m] = global_phase * exp_phi * 1j * sin_t\n",
    "    u_mzi[n, n] = global_phase * cos_t\n",
    "\n",
    "    return u_mzi\n",
    "\n",
    "\n",
    "class MachZehnder(NamedTuple):\n",
    "    theta: float\n",
    "    phi: float\n",
    "    target: Tuple[int, int]\n",
    "\n",
    "\n",
    "class Decomposition(NamedTuple):\n",
    "    D: Tensor\n",
    "    circuit: List[MachZehnder]\n",
    "\n",
    "\n",
    "def _is_unitary(U: Tensor, atol=1e-6) -> bool:\n",
    "    I = torch.eye(U.shape[0], dtype=U.dtype, device=U.device)\n",
    "    return torch.allclose(U @ U.conj().T, I, atol=atol)\n",
    "\n",
    "def clements_decomposition(U: Tensor) -> Decomposition:\n",
    "    if not isinstance(U, torch.Tensor):\n",
    "        raise TypeError(\"U must be a torch.Tensor.\")\n",
    "    if not _is_unitary(U):\n",
    "        raise ValueError(\"U must be a unitary matrix.\")\n",
    "\n",
    "    dim = U.shape[0]\n",
    "    dtype = U.dtype\n",
    "    device = U.device\n",
    "\n",
    "    right_sequence: List[MachZehnder] = []\n",
    "    left_sequence: List[MachZehnder] = []\n",
    "    U = U.clone()\n",
    "\n",
    "    for k in range(1, dim):\n",
    "        if k % 2 == 1:\n",
    "            for i, j in zip(range(dim - 1, dim - k - 1, -1), range(k - 1, -1, -1)):\n",
    "                if torch.abs(U[i, j]) < 1e-12:\n",
    "                    continue\n",
    "                if torch.abs(U[i, j + 1]) < 1e-12:\n",
    "                    phi = 0.0\n",
    "                else:\n",
    "                    phi = (torch.angle(U[i, j] / U[i, j + 1]) - torch.pi / 2) % (2 * torch.pi)\n",
    "                theta = torch.arctan2(torch.abs(U[i, j]), torch.abs(U[i, j + 1]))\n",
    "                right_sequence.append(MachZehnder(theta, phi, (j, j + 1)))\n",
    "                mzi = mzi_matrix(dim, (j, j + 1), theta, phi, dtype=dtype, device=device)\n",
    "                U = U @ mzi.conj().T\n",
    "        else:\n",
    "            for i, j in zip(range(dim - k, dim), range(0, k)):\n",
    "                if torch.abs(U[i, j]) < 1e-12:\n",
    "                    continue\n",
    "                if torch.abs(U[i - 1, j]) < 1e-12:\n",
    "                    phi = 0.0\n",
    "                else:\n",
    "                    phi = (torch.angle(U[i, j] / U[i - 1, j]) + torch.pi / 2) % (2 * torch.pi)\n",
    "                theta = torch.arctan2(torch.abs(U[i, j]), torch.abs(U[i - 1, j]))\n",
    "                left_sequence.insert(0, MachZehnder(theta, phi, (i - 1, i)))\n",
    "                mzi = mzi_matrix(dim, (i - 1, i), theta, phi, dtype=dtype, device=device)\n",
    "                U = mzi @ U\n",
    "\n",
    "    D = torch.diag(U).clone()\n",
    "    new_left_sequence: List[MachZehnder] = []\n",
    "\n",
    "    for theta, phi, (m, n) in left_sequence:\n",
    "        new_phi = (torch.pi + torch.angle(D[m]) - torch.angle(D[n])) % (2 * torch.pi)\n",
    "        new_left_sequence.insert(0, MachZehnder(theta, new_phi, (m, n)))\n",
    "        new_beta = torch.angle(D[n]) - 2 * theta\n",
    "        new_alpha = torch.angle(D[n]) - torch.pi - phi - 2 * theta\n",
    "        D[m] = torch.exp(1j * new_alpha)\n",
    "        D[n] = torch.exp(1j * new_beta)\n",
    "\n",
    "    return Decomposition(D=D, circuit=new_left_sequence + right_sequence[::-1])\n",
    "\n",
    "def circuit_reconstruction(decomposition: Decomposition) -> Tensor:\n",
    "    if not isinstance(decomposition, Decomposition):\n",
    "        raise TypeError(\"decomposition must be a Decomposition object.\")\n",
    "\n",
    "    D = decomposition.D\n",
    "    dim = D.shape[0]\n",
    "    dtype = D.dtype\n",
    "    device = D.device\n",
    "\n",
    "    reconstructed_matrix = torch.diag(D)\n",
    "\n",
    "    for theta, phi, (m, n) in decomposition.circuit:\n",
    "        mzi = mzi_matrix(dim, (m, n), theta, phi, dtype=dtype, device=device)\n",
    "        reconstructed_matrix = reconstructed_matrix @ mzi\n",
    "\n",
    "    return reconstructed_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разложение Река"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Unitary:\n",
      " [[-0.2006+0.0945j  0.5269-0.099j  -0.2327+0.2757j  0.008 +0.1147j\n",
      "  -0.0506+0.092j  -0.1041-0.2304j -0.3972+0.4805j -0.0954-0.2177j]\n",
      " [-0.1295-0.1587j  0.1815+0.1986j -0.0996-0.1983j -0.3697+0.4263j\n",
      "  -0.1729-0.019j  -0.4346+0.3077j  0.2055+0.1765j  0.1376+0.3344j]\n",
      " [-0.3724-0.5003j -0.1125-0.2725j -0.0402+0.2994j -0.3849-0.0267j\n",
      "   0.393 +0.2562j  0.1423+0.1155j -0.0635-0.1336j -0.0753+0.0523j]\n",
      " [-0.1528+0.2489j -0.0655+0.3764j  0.1486+0.1059j -0.2019-0.1234j\n",
      "  -0.3107+0.3058j  0.3503+0.3919j  0.0303+0.1637j -0.4256-0.0662j]\n",
      " [-0.0238-0.1727j -0.3071+0.078j   0.1853-0.2987j  0.0207+0.0415j\n",
      "   0.0188+0.4263j  0.1027-0.1532j  0.0292+0.4863j  0.4608-0.2788j]\n",
      " [ 0.1624+0.2351j  0.2311-0.0187j  0.1415-0.227j  -0.1423-0.3131j\n",
      "   0.5125-0.1013j -0.0614+0.5134j -0.2805+0.1268j  0.1911-0.0567j]\n",
      " [-0.0476+0.3983j -0.4043-0.1464j -0.6899-0.1172j -0.0803-0.118j\n",
      "   0.0564+0.1781j -0.0128-0.0217j -0.0923+0.1006j  0.0269+0.2987j]\n",
      " [ 0.3913+0.092j  -0.2228-0.1365j  0.0504-0.0933j -0.1269+0.5538j\n",
      "   0.0821+0.2279j -0.1875+0.0743j -0.3142-0.1974j -0.3094-0.3214j]]\n",
      "\n",
      "Circuit:\n",
      "\n",
      "Layer 1\n",
      "\n",
      "theta: 1.014, phi: 0.25, target: (5, 6)\n",
      "theta: 0.859, phi: 0.93, target: (6, 7)\n",
      "\n",
      "Layer 2\n",
      "\n",
      "theta: 0.869, phi: 1.48, target: (3, 4)\n",
      "theta: 1.152, phi: 3.80, target: (4, 5)\n",
      "theta: 1.222, phi: 3.01, target: (5, 6)\n",
      "theta: 1.207, phi: 0.50, target: (6, 7)\n",
      "\n",
      "Layer 3\n",
      "\n",
      "theta: 1.211, phi: 4.92, target: (1, 2)\n",
      "theta: 0.706, phi: 6.17, target: (2, 3)\n",
      "theta: 1.168, phi: 6.00, target: (3, 4)\n",
      "theta: 1.482, phi: 1.23, target: (4, 5)\n",
      "theta: 0.983, phi: 4.18, target: (5, 6)\n",
      "theta: 0.860, phi: 3.11, target: (6, 7)\n",
      "\n",
      "Layer 4\n",
      "\n",
      "theta: 1.294, phi: 2.22, target: (0, 1)\n",
      "theta: 0.949, phi: 4.89, target: (1, 2)\n",
      "theta: 1.519, phi: 2.29, target: (2, 3)\n",
      "theta: 1.284, phi: 2.41, target: (3, 4)\n",
      "theta: 1.242, phi: 3.30, target: (4, 5)\n",
      "theta: 1.226, phi: 3.18, target: (5, 6)\n",
      "theta: 0.364, phi: 5.82, target: (6, 7)\n",
      "\n",
      "Layer 5\n",
      "\n",
      "theta: 1.369, phi: 2.81, target: (0, 1)\n",
      "theta: 0.861, phi: 4.16, target: (1, 2)\n",
      "theta: 1.240, phi: 1.06, target: (2, 3)\n",
      "theta: 0.855, phi: 4.66, target: (3, 4)\n",
      "theta: 0.532, phi: 1.24, target: (4, 5)\n",
      "\n",
      "Layer 6\n",
      "\n",
      "theta: 0.946, phi: 2.99, target: (0, 1)\n",
      "theta: 0.842, phi: 1.56, target: (1, 2)\n",
      "theta: 0.830, phi: 3.45, target: (2, 3)\n",
      "\n",
      "Layer 7\n",
      "\n",
      "theta: 0.994, phi: 1.25, target: (0, 1)\n",
      "\n",
      "Reconstructed Unitary:\n",
      " [[-0.2006+0.0945j  0.5269-0.099j  -0.2327+0.2757j  0.008 +0.1147j\n",
      "  -0.0506+0.092j  -0.1041-0.2304j -0.3972+0.4805j -0.0954-0.2177j]\n",
      " [-0.1295-0.1587j  0.1815+0.1986j -0.0996-0.1983j -0.3697+0.4263j\n",
      "  -0.1729-0.019j  -0.4346+0.3077j  0.2055+0.1765j  0.1376+0.3344j]\n",
      " [-0.3724-0.5003j -0.1125-0.2725j -0.0402+0.2994j -0.3849-0.0267j\n",
      "   0.393 +0.2562j  0.1423+0.1155j -0.0635-0.1336j -0.0753+0.0523j]\n",
      " [-0.1528+0.2489j -0.0655+0.3764j  0.1486+0.1059j -0.2019-0.1234j\n",
      "  -0.3107+0.3058j  0.3503+0.3919j  0.0303+0.1637j -0.4256-0.0662j]\n",
      " [-0.0238-0.1727j -0.3071+0.078j   0.1853-0.2987j  0.0207+0.0415j\n",
      "   0.0188+0.4263j  0.1027-0.1532j  0.0292+0.4863j  0.4608-0.2788j]\n",
      " [ 0.1624+0.2351j  0.2311-0.0187j  0.1415-0.227j  -0.1423-0.3131j\n",
      "   0.5125-0.1013j -0.0614+0.5134j -0.2805+0.1268j  0.1911-0.0567j]\n",
      " [-0.0476+0.3983j -0.4043-0.1464j -0.6899-0.1172j -0.0803-0.118j\n",
      "   0.0564+0.1781j -0.0128-0.0217j -0.0923+0.1006j  0.0269+0.2987j]\n",
      " [ 0.3913+0.092j  -0.2228-0.1365j  0.0504-0.0933j -0.1269+0.5538j\n",
      "   0.0821+0.2279j -0.1875+0.0743j -0.3142-0.1974j -0.3094-0.3214j]]\n",
      "\n",
      "Fidellity:\n",
      " 0.99999992328784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/5xcctjn15052xcf5hwdbv_6h0000gp/T/ipykernel_98493/511947677.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  theta_t = torch.tensor(theta, dtype=torch.float32, device=device, requires_grad=False)\n",
      "/var/folders/86/5xcctjn15052xcf5hwdbv_6h0000gp/T/ipykernel_98493/511947677.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  phi_t = torch.tensor(phi, dtype=torch.float32, device=device, requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def fidellity(U_exp: Tensor, U: Tensor):\n",
    "    return torch.abs(torch.einsum('ii', U_exp.adjoint() @ U)).item()/U.shape[0]\n",
    "\n",
    "def haar_measure(N):\n",
    "    \"\"\"Generate a Haar-random matrix using the QR decomposition.\"\"\"\n",
    "    A, B = torch.randn(size=(N, N), dtype=torch.float64), torch.randn(size=(N, N), dtype=torch.float64)\n",
    "    Z = A + 1j * B\n",
    "    Q, R = torch.linalg.qr(Z)\n",
    "    Lambda = torch.diag(torch.tensor([R[i, i] / torch.abs(R[i, i]) for i in range(N)]))\n",
    "\n",
    "    return Q @ Lambda\n",
    "\n",
    "N = torch.randint(low=2, high=20, size = ())\n",
    "U = haar_measure(N)\n",
    "\n",
    "print(\"Initial Unitary:\\n\", U.numpy().round(4))\n",
    "\n",
    "# Apply Clements decomposition\n",
    "decomposition = clements_decomposition(U)\n",
    "\n",
    "# Print the decomposition parameters\n",
    "print(\"\\nCircuit:\\n\")\n",
    "num_layer = 1\n",
    "temp = 0\n",
    "print(f'Layer {num_layer}\\n')\n",
    "for theta, phi, target in decomposition.circuit:\n",
    "    if temp > target[0]:\n",
    "        num_layer += 1\n",
    "        print(f'\\nLayer {num_layer}\\n')\n",
    "    print(f\"theta: {theta:.3f}, phi: {phi:.2f}, target: {target}\")\n",
    "    temp = target[0]\n",
    "\n",
    "# Reconstruct the unitary from the decomposition\n",
    "reconstructed_unitary = circuit_reconstruction(decomposition)\n",
    "\n",
    "# Print the reconstructed unitary and assert initial matrix\n",
    "print(\"\\nReconstructed Unitary:\\n\", reconstructed_unitary.numpy().round(4))\n",
    "print(\"\\nFidellity:\\n\", fidellity(reconstructed_unitary, U))\n",
    "assert torch.allclose(U, reconstructed_unitary, atol=1e-06), \"Reconstructed unitary does not match original.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
